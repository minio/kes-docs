---
title: Hashicorp Vault Keystore
date: 2023-02-08
lastmod: :git
draft: false
tableOfContents: true
---

This tutorial shows how to setup a KES server that uses [Vault's K/V engine](https://developer.hashicorp.com/vault/docs/secrets/kv) as a persistent and secure key store:

```goat
                 +------------------------------------+
 .----------.    |    .----------.     .---------.    |
| KES Client +---+---+ KES Server +---+   Vault   |   |
 '----------'    |    '----------'     '---------'    |
                 +------------------------------------+
```

## Vault Server Setup

1. Generate Vault Private Key & Certificate

   KES and Vault exchange sensitive information. 
   In particular, KES sends and receives the secret keys from Vault's HTTP API. 
   Therefore, it is necessary to secure the communication between KES and Vault. 
   
   Here, we use self-signed certificates for simplicity.
   
   The following command generates a new TLS private key (`vault.key`) and a self-signed X.509 certificate (`vault.crt`) issued for the IP `127.0.0.1` and DNS name `localhost`: 
   
   ```sh
   $ kes identity new --key vault.key --cert vault.crt --ip "127.0.0.1" localhost
   
     Private key:  vault.key
     Certificate:  vault.crt
     Identity:     37ced4538faa0c236b9fa80826b50de9afb45cc29acf6575f069a2d10e6125af
   ```
   
   {{< admonition type="note" >}}
   If you already have a TLS private key & certificate, such as from WebPKI or an internal CA, you can use them instead. 
   Remember to adjust the `vault-config.json` later on.
   {{< /admonition >}}

2. Configure Vault Server

   The following `vault-config.json` starts a single Vault server instance on port `8200`: 
   
   ```json {.copy}
   {
     "api_addr": "https://127.0.0.1:8200",
     "backend": {
       "file": {
         "path": "vault/file"
       }
     },
   
     "default_lease_ttl": "168h",
     "max_lease_ttl": "720h",
   
     "listener": {
       "tcp": {
         "address": "0.0.0.0:8200",
         "tls_cert_file": "vault.crt",
         "tls_key_file": "vault.key",
         "tls_min_version": "tls12"
       }
     }
   }
   ```

   {{< admonition type="note">}}
   Note that we run Vault with a file backend. 
   For high-availability you may want to use [etcd](https://www.vaultproject.io/docs/configuration/storage/etcd.html), [consul](https://www.vaultproject.io/docs/configuration/storage/consul.html), or Vault with [integrated storage](https://learn.hashicorp.com/vault/operations/raft-reference-architectur) instead.
   {{< /admonition >}}

3. Start Vault Server

   Download the [Vault binary](https://www.vaultproject.io/downloads/).
   
   {{< admonition title="Linux Swap Protection" type="note">}}
   On linux, we can grant the binary the `ipc_lock` capability such that it can use the [`mlock`](http://man7.org/linux/man-pages/man2/mlock.2.html) syscall without root permissions:
   
   ```sh {.copy}
   sudo setcap cap_ipc_lock=+ep $(readlink -f $(which vault))
   ```
   {{< /admonition >}}
   
   Start the Vault server instance:
   ```
   $ vault server -config vault-config.json
   ```

4. Set `VAULT_ADDR` endpoint

   The Vault CLI needs to know the Vault endpoint:
   
   ```sh {.copy}
   export VAULT_ADDR='https://127.0.0.1:8200'
   ```
   
   {{< admonition title="Self-signed Certificates" type="tip" >}}   
   When using a self-signed `vault.crt` the Vault CLI also needs to skip TLS certificate verification to talk to the Vault server:
   
   ```sh {.copy}
   export VAULT_SKIP_VERIFY=true
   ```
   {{< /admonition >}}

5. Initialize Vault Server

   ```sh
   $ vault operator init
   
   Unseal Key 1: eyW/+8ZtsgT81Cb0e8OVxzJAQP5lY7Dcamnze+JnWEDT
   Unseal Key 2: 0tZn+7QQCxphpHwTm6/dC3LpP5JGIbYl6PK8Sy79R+P2
   Unseal Key 3: cmhs+AUMXUuB6Lzsvgcbp3bRT6VDGQjgCBwB2xm0ANeF
   Unseal Key 4: /fTPpec5fWpGqWHK+uhnnTNMQyAbl5alUi4iq2yNgyqj
   Unseal Key 5: UPdDVPto+H6ko+20NKmagK40MOskqOBw4y/S51WpgVy/
    
   Initial Root Token: s.zaU4Gbcu0Wh46uj2V3VuUde0
   
   Vault is initialized with 5 key shares and a key threshold of 3. Please securely
   distribute the key shares printed above. When the Vault is re-sealed,
   restarted, or stopped, you must supply at least 3 of these keys to unseal it
   before it can start servicing requests.
   ```

   {{< admonition type="warning">}}
   Vault prints `N` (5 by default) unseal key shares.
   Vault requires at least `M` (3 by default) unseal key shares to re-generate the actual unseal key to unseal Vault. 
   Therefore, make sure to store them at a secure and durable location.
   {{< /admonition >}}

6. Set `VAULT_TOKEN`

   The Vault CLI needs an authentication token to perform operations.
   The root access token is generated by `vault operator init`.
   
   ```sh {.copy}
   export VAULT_TOKEN=s.zaU4Gbcu0Wh46uj2V3VuUde0
   ```

   Adjust the token to your own Vault access token.

7. Unseal Vault Server

   Once initialized, unseal the Vault using `M` out of `N` unseal key shares:
   
   ```sh {.copy}
   vault operator unseal eyW/+8ZtsgT81Cb0e8OVxzJAQP5lY7Dcamnze+JnWEDT
   ```
   ```sh {.copy}
   vault operator unseal 0tZn+7QQCxphpHwTm6/dC3LpP5JGIbYl6PK8Sy79R+P2
   ```
   ```sh {.copy}
   vault operator unseal cmhs+AUMXUuB6Lzsvgcbp3bRT6VDGQjgCBwB2xm0ANeF
   ```
   
   After submitting enough valid unseal key shares, Vault unseals and can process requests.

8. Enable `K/V` Backend

   KES stores the secret keys at the Vault K/V backend. 
   Vault provides two [K/V engines](https://www.vaultproject.io/docs/secrets/kv), `v1` and `v2`.
   
   MinIO recommends the K/V `v1` engine.

   {{< tabs "aws-config" >}}
   {{< tab "Vault Engine v1" >}}

   The following command enables the K/V `v1` secret engine:

   ```sh {.copy}
   vault secrets enable -version=1 kv
   ```
   
   {{< /tab >}}

   {{< tab "Vault Engine v2" >}}

   The following command enables the K/V `v2` secret engine:
   
   ```sh {.copy}
   $ vault secrets enable -version=2 kv
   ```
   {{< /tab> }}
   {{< /tabs >}}

   {{< admonition type="note" >}}
   Note that the Vault policy for KES depends on the chosen K/V engine version.
   The `v2` engine requires slightly different policy rules compared to the `v1` engine. 
   For more information about migrating from  `v1` to `v2` see [upgrading from v1](https://www.vaultproject.io/docs/secrets/kv/kv-v2#upgrading-from-version-1).
   {{< /admonition >}}
   
9. Create Vault Policy

   The Vault policy defines the API paths the KES server can access.
   
   - For `v1` 
    
     The following `kes-policy.hcl` policy should be used for the K/V `v1` backend:
    
     ```hcl {.copy}
     path "kv/*" {
        capabilities = [ "create", "read", "delete" ]
     }
     ```
   
   - For `v2` T
     The following `kes-policy.hcl` policy should be used for the K/V `v2` backend:
  
     ```hcl {.copy}
     path "kv/data/*" {
        capabilities = [ "create", "read" ]
     }
     path "kv/metadata/*" {
        capabilities = [ "list", "delete" ]       
     }
     ```
   
   The following command creates the policy at Vault:

   ```sh {.copy}
   vault policy write kes-policy kes-policy.hcl
   ```

10. Enable AppRole Authentication

    This step allows the KES server to authenticate to Vault. 
    For this tutorial, we use the AppRole authentication method. 
    
    ```sh {.copy}
    vault auth enable approle
    ```
    
11. Create KES Role

    The following command adds a new role `kes-server` at Vault:
    
    ```sh {.copy}
    vault write auth/approle/role/kes-server token_num_uses=0  secret_id_num_uses=0  period=5m
    ```

12. Bind Policy to Role

    The following command binds `kes-server` role to the `key-policy`:
    ```sh {.copy}
    vault write auth/approle/role/kes-server policies=kes-policy
    ```

13. Generate AppRole ID

    Request an AppRole ID for the KES server:
    ```sh {.copy}
    vault read auth/approle/role/kes-server/role-id 
    ```

14. Generate AppRole Secret

    Request an AppRole secret for the KES server:
    
    ```sh {.copy}
    vault write -f auth/approle/role/kes-server/secret-id 
    ```
    
    The AppRole secret prints as `secret_id`. 
    You can ignore the `secret_id_accessor`. 

## KES Server Setup

1. Generate KES Server Private Key & Certificate

   The following command generates a new TLS private key `server.key` and a self-signed X.509 certificate `server.cert` that is issued for the IP `127.0.0.1` and DNS name `localhost` (as SAN). 
   Customize the command to match your setup.
   
   ```sh {.copy}
   kes tool identity new --server --key server.key --cert server.cert --ip "127.0.0.1" --dns localhost
   ```
   
   {{< admonition type="tip" >}}
   Any other tooling for X.509 certificate generation works as well. 
   For example, you could use `openssl`:
   
   ```sh {.copy}
   $ openssl ecparam -genkey -name prime256v1 | openssl ec -out server.key
   
   $ openssl req -new -x509 -days 30 -key server.key -out server.cert \
       -subj "/C=/ST=/L=/O=/CN=localhost" -addext "subjectAltName = IP:127.0.0.1"
   ```
   {{< /admonition >}}

2. Generate Client Credentials

   The following command generates a new TLS private/public key pair for the client application to use for the KES Server:

   ```sh
   $ kes identity new --key=client.key --cert=client.crt MyApp
   
     Private key:  client.key
     Certificate:  client.crt
     Identity:     02ef5321ca409dbc7b10e7e8ee44d1c3b91e4bf6e2198befdebee6312745267b
   ```
   
   The identity `02ef5321ca409dbc7b10e7e8ee44d1c3b91e4bf6e2198befdebee6312745267b` is a unique fingerprint of the public key in `client.crt`. 
   You can re-compute it anytime:
   
   ```sh
   $ kes identity of client.crt
   
     Identity:  02ef5321ca409dbc7b10e7e8ee44d1c3b91e4bf6e2198befdebee6312745267b
   ```

3. Configure KES Server

   Create the KES server configuration file: `config.yml`.
   
   Make sure that the identity in the policy section matches the `client.crt` identity.
   Add the approle `role_id` and `secret_id` obtained earlier.
   
   ```yaml {.copy}
   address: 0.0.0.0:7373 # Listen on all network interfaces on port 7373
   
   admin:
     identity: disabled  # We disable the admin identity since we don't need it in this guide 
      
   tls:
     key: private.key    # The KES server TLS private key
     cert: public.crt    # The KES server TLS certificate
      
   policy:
     my-app: 
       allow:
       - /v1/key/create/my-key*
       - /v1/key/generate/my-key*
       - /v1/key/decrypt/my-key*
       identities:
       - 02ef5321ca409dbc7b10e7e8ee44d1c3b91e4bf6e2198befdebee6312745267b # Use the identity of your client.crt
      
   keystore:
      vault:
        endpoint: https://127.0.0.1:8200
        version:  v1 # The K/V engine version - either "v1" or "v2".
        approle:
          id:     "" # Your AppRole ID
          secret: "" # Your AppRole Secret
          retry:  15s
        status:
          ping: 10s
        tls:
          ca: vault.crt # Manually trust the vault certificate since we use self-signed certificates
   ```

4. Start KES Server
  
   {{ tabs "Vault Initializatio" }}
   {{ tab "Linux" }}

   ```sh {.copy}
   kes server --config config.yml --auth off
   ```

   {{< admonition title="Linux Swap Protection" type="tip" >}}

   In Linux environments, KES can use the [`mlock`](http://man7.org/linux/man-pages/man2/mlock.2.html) syscall to prevent the OS from writing in-memory data to disk (swapping). 
   This prevents leaking sensitive data.
   
   Use the following command to allow KES to use the mlock syscall without running with `root` privileges:

   ```sh {.copy}
   $ sudo setcap cap_ipc_lock=+ep $(readlink -f $(which kes))
   ```

   Start a KES server instance with memory protection:
   
   ```sh {.copy}
   kes server --config config.yml --auth off --mlock
   ```
   {{< /admonition >}}

   {{ /tab }}

   {{ tab "Container" }}

   The instructions use [Podman](https://podman.io/) to manage the containers.
   You can accomplish similar with Docker, if preferred.

   Modify addresses and file paths as needed for your deployment.

   ```sh {.copy}
   sudo podman pod create  \
     -p 9000:9000 -p 9001:9001 -p 7373:7373  \
     -v ~/minio-kes-vault/certs:/certs  \
     -v ~/minio-kes-vault/minio:/mnt/minio  \
     -v ~/minio-kes-vault/config:/etc/default/  \
     -n minio-kes-vault
   
   sudo podman run -dt  \
     --cap-add IPC_LOCK  \
     --name kes-server  \
     --pod "minio-kes-vault"  \
     -e KES_SERVER=https://127.0.0.1:7373  \
     -e KES_CLIENT_KEY=/certs/kes-server.key  \
     -e KES_CLIENT_CERT=/certs/kes-server.cert  \
     quay.io/minio/kes:2024-01-11T13-09-29Z server  \
       --auth  \
       --config=/etc/default/kes-config.yaml  \
   
   sudo podman run -dt  \
     --name minio-server  \
     --pod "minio-kes-vault"  \
     -e "MINIO_CONFIG_ENV_FILE=/etc/default/minio"  \
     quay.io/minio/minio:RELEASE.2024-01-31T20-20-33Z server  \
       --console-address ":9001"
   ```

   You can verify the status of the containers using the following command.
   The command should show three pods, one for hte Pod, one for KES, and one for MinIO.

   ```sh {.copy}
   sudo podman container list
   ```


   {{ /tab }}
   {{ /tabs }}

## KES CLI Access

1. Set `KES_SERVER` Endpoint

   The following environment variable specifies the server the KES CLI should talk to:

   ```sh {.copy}
   export KES_SERVER=https://127.0.0.1:7373
   ```

2. Define the Client Credentials

   The following environment variables set the access credentials the client uses to talk to a KES server:
   
   ```sh {.copy}
   export KES_CLIENT_CERT=client.crt
   ```
   ```sh {.copy}
   export KES_CLIENT_KEY=client.key
   ```

3. Test the Configuration
   
   Perform any API operation allowed by the policy we assigned above. 
   
   For example, create a key:

   ```sh {.copy}
   kes key create my-key-1
   ```
   
   Use the key to generate a new data encryption key:

   ```sh
   $ kes key dek my-key-1
   {
     plaintext : UGgcVBgyQYwxKzve7UJNV5x8aTiPJFoR+s828reNjh0=
     ciphertext: eyJhZWFkIjoiQUVTLTI1Ni1HQ00tSE1BQy1TSEEtMjU2IiwiaWQiOiIxMTc1ZjJjNDMyMjNjNjNmNjY1MDk5ZDExNmU3Yzc4NCIsIml2IjoiVHBtbHpWTDh5a2t4VVREV1RSTU5Tdz09Iiwibm9uY2UiOiJkeGl0R3A3bFB6S21rTE5HIiwiYnl0ZXMiOiJaaWdobEZrTUFuVVBWSG0wZDhSYUNBY3pnRWRsQzJqWFhCK1YxaWl2MXdnYjhBRytuTWx0Y3BGK0RtV1VoNkZaIn0=
   }
   ```

   To run KES locally for testing purposes, use the `-k` or `-insecure` flag to generate a new data encryption key:

   ```sh
   $ kes key dek my-key-1 -k
   {
     plaintext : UGgcVBgyQYwxKzve7UJNV5x8aTiPJFoR+s828reNjh0=
     ciphertext: eyJhZWFkIjoiQUVTLTI1Ni1HQ00tSE1BQy1TSEEtMjU2IiwiaWQiOiIxMTc1ZjJjNDMyMjNjNjNmNjY1MDk5ZDExNmU3Yzc4NCIsIml2IjoiVHBtbHpWTDh5a2t4VVREV1RSTU5Tdz09Iiwibm9uY2UiOiJkeGl0R3A3bFB6S21rTE5HIiwiYnl0ZXMiOiJaaWdobEZrTUFuVVBWSG0wZDhSYUNBY3pnRWRsQzJqWFhCK1YxaWl2MXdnYjhBRytuTWx0Y3BGK0RtV1VoNkZaIn0=
   }
      ```

## Using KES with a MinIO Server

MinIO Server requires KES to set up server-side data encryption.

See the [KES for MinIO instruction guide]({{< relref "/tutorials/kes-for-minio.md" >}}) for additional steps needed to use your new KES Server with a MinIO Server.

## Configuration References

The following section describes each of the Key Encryption Service (KES) configuration settings for using AWS Secrets Manager and AWS Key Management System as the root KMS for Server Side Encryption with KES.

{{< admonition title="MinIO Server Requires Expanded Permissions" type="important" >}}
Starting with [MinIO Server RELEASE.2023-02-17T17-52-43Z](https://github.com/minio/minio/releases/tag/RELEASE.2023-02-17T17-52-43Z), MinIO requires expanded KES permissions for functionality. 
The example configuration in this section contains all required permissions.
{{< /admonition >}}


{{< tabs "vault-config" >}}
{{< tab "YAML Overview" >}}
Fields with `${<STRING>}` use the environment variable matching the `<STRING>` value. 
You can use this functionality to set credentials without writing them to the configuration file.

The YAML assumes a minimal set of permissions for the MinIO deployment accessing KES. 
As an alternative, you can omit the `policy.minio-server` section and instead set the `${MINIO_IDENTITY}` hash as the `${ROOT_IDENTITY}`.

```yaml {.copy}
address: 0.0.0.0:7373
root: ${ROOT_IDENTITY}

tls:
  key: kes-server.key
  cert: kes-server.cert

api:
  /v1/ready:
    skip_auth: false
    timeout:   15s

policy:
  minio-server:
    allow:
    - /v1/key/create/*
    - /v1/key/generate/*
    - /v1/key/decrypt/*
    - /v1/key/bulk/decrypt
    - /v1/key/list/*
    - /v1/status
    - /v1/metrics
    - /v1/log/audit
    - /v1/log/error
    deny:
    - /v1/key/generate/my-app-internal*
    - /v1/key/decrypt/my-app-internal*
    identities:
    - ${MINIO_IDENTITY}

    my-app:
    allow:
    - /v1/key/create/my-app*
    - /v1/key/generate/my-app*
    - /v1/key/decrypt/my-app*
    deny:
    - /v1/key/generate/my-app-internal*
    - /v1/key/decrypt/my-app-internal*
    identities:
    - df7281ca3fed4ef7d06297eb7cb9d590a4edc863b4425f4762bb2afaebfd3258
    - c0ecd5962eaf937422268b80a93dde4786dc9783fb2480ddea0f3e5fe471a731

keys:
  - name: "minio-encryption-key-alpha"
  - name: "minio-encryption-key-baker"
  - name: "minio-encryption-key-charlie"

cache:
  expiry:
    any: 5m0s
    unused: 20s
    offline: 0s

# The following log configuration only affects logging to console.
log:

  # Enable/Disable logging error events to STDERR. Valid values
  # are "on" or "off". If not set the default is "on". If no error
  # events should be logged to STDERR it has to be set explicitly
  # to: "off".
  error: on

  # Enable/Disable logging audit events to STDOUT. Valid values
  # are "on" and "off". If not set the default is "off".
  # Logging audit events to STDOUT may flood your console since
  # there will be one audit log event per request-response pair.
  audit: off

keystore:
  vault:
    endpoint: ""  # The Vault endpoint - e.g. https://127.0.0.1:8200
    engine: ""    # The path of the K/V engine - e.g. secrets. If empty, defaults to: kv. (Vault default)
    version: ""   # The K/V engine version - either "v1" or "v2". The "v1" engine is recommended.
    namespace: "" # An optional Vault namespace. See: https://www.vaultproject.io/docs/enterprise/namespaces/index.html
    prefix: ""    # An optional K/V prefix. The server will store keys under this prefix.
    transit:      # Optionally encrypt keys stored on the K/V engine with a Vault-managed key.
      engine: ""  # The path of the transit engine - e.g. "my-transit". If empty, defaults to: transit (Vault default)
      key: ""     # The key name that should be used to encrypt entries stored on the K/V engine.
    approle:    # AppRole credentials. See: https://www.vaultproject.io/docs/auth/approle.html
      namespace: "" # Optional Vault namespace used just for authentication. A single "/" is an alias for the Vault root namespace.
      engine: ""    # The path of the AppRole engine - e.g. authenticate. If empty, defaults to: approle. (Vault default)
      id: ""        # Your AppRole Role ID
      secret: ""    # Your AppRole Secret ID
    kubernetes: # Kubernetes credentials. See: https://www.vaultproject.io/docs/auth/kubernetes
      namespace: "" # Optional Vault namespace used just for authentication. A single "/" is an alias for the Vault root namespace.
      engine: ""    # The path of the Kubernetes engine e.g. authenticate. If empty, defaults to: kubernetes. (Vault default)
      role: ""      # The Kubernetes JWT role
      jwt:  ""      # Either the JWT provided by K8S or a path to a K8S secret containing the JWT.
    tls:        # The Vault client TLS configuration for mTLS authentication and certificate verification
      key: ""     # Path to the TLS client private key for mTLS authentication to Vault
      cert: ""    # Path to the TLS client certificate for mTLS authentication to Vault
      ca: ""      # Path to one or multiple PEM root CA certificates
    status:     # Vault status configuration. The server will periodically reach out to Vault to check its status.
      ping: 10s   # Duration until the server checks Vault's status again.
```

{{< /tab >}}

{{< tab "Reference" >}}

For complete documentation, see the [configuration page]({{< relref "/tutorials/configuration.md" >}}).

| <div style="width:150px"> Key  </div>                        | Description                    |
|-----------------------------|--------------------------------|
| `address`                     | The network address and port the KES server listens to on startup. Defaults to port `7373` on all host network interfaces. |
| `root`                        | The identity for the KES superuser (`root`) identity. Clients connecting with a TLS certificate whose hash (`kes identity of client.cert`) matches this value have access to all KES API operations. Specify `disabled` to remove the root identity and rely only on the `policy` configuration for controlling identity and access management to KES. |
| `tls`                         | The TLS private key and certificate used by KES for establishing TLS-secured communications. Specify the full path for both the private `.key` and public `.cert` to the `key` and `cert` fields, respectively. |
| `policy`                      | Specify one or more [policies]({{< relref "/tutorials/configuration.md#policy-configuration" >}}) to control access to the KES server. MinIO SSE requires access to the following KES cryptographic APIs: <br><br> `/v1/key/create/*` <br> `/v1/key/generate/*` <br> `/v1/key/decrypt/*` <br><br> Specifying additional keys does not expand MinIO SSE functionality and may violate security best practices around providing unnecessary client access to cryptographic key operations. <br><br> You can restrict the range of key names MinIO can create as part of performing SSE by specifying a prefix before the `*.` For example, `minio-sse-*` only grants access to `create`, `generate`, or `decrypt` keys using the `minio-sse-` prefix. <br><br>KES uses mTLS to authorize connecting clients by comparing the hash of the TLS certificate against the `identities` of each configured policy. Use the `kes identity of` command to compute the identity of the MinIO mTLS certificate and add it to the `policy.<NAME>.identities` array to associate MinIO to the `<NAME>` policy. |
| `keys`                        | Specify an array of keys which *must* exist on the root KMS for KES to successfully start. KES attempts to create the keys if they do not exist and exits with an error if it fails to create any key. KES does not accept any client requests until it completes validation of all specified keys.|
| `cache`                       | Specify expiration of cached keys in `#d#h#m#s` format. Unexpired keys may be used in the event the KMS becomes temporarily unavailable. <br><br> Entries may be set for `any` key, `unused` keys, or `offline` keys. <br><br> If not set, KES uses values of `5m` for all keys, `20s` for unused keys, and `0s` for offline keys. |
| `log`                         | Enable or disable output for `error` and `audit` type logging events to the console. |
| `keystore.vault.endpoint` | The Vault endpoint. For example, `https://127.0.0.1:8200` |
| `keystore.vault.engine` | The path of the K/V engine. For example, `secrets`. <br><br> If empty, defaults to: `kv` (Vault default).  |
| `keystore.vault.version` | The K/V engine version, either `v1` or `v2`. `v1` engine is recommended. |
| `keystore.vault.namespace` | An optional [Vault namespace](https://www.vaultproject.io/docs/enterprise/namespaces/index.html). |
| `keystore.vault.prefix` | An optional K/V prefix. The server stores keys under this prefix. |
| `keystore.vault.transit` | Optionally encrypt keys stored on the K/V engine with a Vault-managed key. |
| `keystore.vault.transit.engine` | The path of the transit engine. For example, `my-transit`. <br><br> If empty, it defaults to: `transit` (Vault default). |
| `keystore.vault.transit.key` | The key name to use to encrypt entries stored on the K/V engine. |
| `keystore.vault.approle` | [AppRole credentials](https://www.vaultproject.io/docs/auth/approle.html). |
| `keystore.vault.approle.namespace` | Optional Vault namespace used just for authentication. A single `/` is an alias for the Vault `root` namespace. |
| `keystore.vault.approle.engine` | The path of the AppRole engine. For example, `authenticate`. <br><br> If empty, defaults to: `approle` (Vault default). |
| `keystore.vault.approle.id` | Your AppRole Role ID |
| `keystore.vault.approle.secret` | Your AppRole ID's secret |
| `keystore.vault.kubernetes` | [Kubernetes credentials](https://www.vaultproject.io/docs/auth/kubernetes). |
| `keystore.vault.kubernetes.namespace` | Optional Vault namespace used just for authentication. A single `/` is an alias for the Vault `root` namespace. |
| `keystore.vault.kubernetes.engine` | The path of the Kubernetes engine. For example, `authenticate`. If empty, defaults to: `kubernetes` (Vault default). |
| `keystore.vault.kubernetes.role` | The Kubernetes JWT's role |
| `keystore.vault.kubernetes.jwt` | Either the JWT provided by Kubernetes or a path to a [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/) containing the JWT. |
| `keystore.vault.tls` | The Vault client TLS configuration for mTLS authentication and certificate verification. |
| `keystore.vault.tls.key` | Path to the TLS client private key for mTLS authentication to Vault. |
| `keystore.vault.tls.cert` | Path to the TLS client certificate for mTLS authentication to Vault. |
| `keystore.vault.tls.ca` | Path to one or multiple PEM root CA certificates. |
| `keystore.vault.status` | Vault status configuration. The server will periodically reach out to Vault to check its status. |
| `keystore.vault.status.ping` | Duration until the server checks Vault's status again. For example, `10s`. |
{{< /tab >}}
{{< /tabs >}}

## Advanced Configuration

These additional configuration steps may solve specific problems.

### Multi-Tenancy with K/V prefixes

Vault can serve as backend for multiple, isolated KES tenants.
Each KES tenant can consist of `N` replicas.
There can be `M` KES tenants connected to the same Vault server/cluster. 

This means `N × M` KES server instances can connect to a single Vault.

In these configurations, each KES tenant has a separate prefix at the K/V secret engine. 
For each KES tenant, there must be a corresponding Vault policy.

- For K/V `v1`:

  ```hcl {.copy}
  path "kv/<tenant-name>/*" {
     capabilities = [ "create", "read", "delete" ]
  }
  ```
   
- For K/V `v2`:
   
  ```hcl {.copy}
  path "kv/data/<tenant-name>/*" {
    capabilities = [ "create", "read" ]
  }
  path "kv/metadata/<tenant-name>/*" {
    capabilities = [ "list", "delete" ]       
  }
  ```

Create a different configuration file for each KES tenant.
The file contains the Vault K/V prefix for the tenant to use.

```yaml {.copy}
keystore:
   vault:
     endpoint: https://127.0.0.1:8200
     prefix: <tenant-name>
     approle:
       id:     "" # Your AppRole ID
       secret: "" # Your AppRole Secret
       retry:  15s
     status:
       ping: 10s
     tls:
       ca: vault.crt # Manually trust the vault certificate since we use self-signed certificates
```

### Multi-Tenancy with Vault Namespaces

Vault can serve as the backend for multiple, isolated KES tenants.
Each KES tenant can consist of `N` replicas.
There can be `M` KES tenants connected to the same Vault server/cluster. 

This means `N × M` KES server instances can connect to a single Vault.

Therefore, each KES tenant has a separate prefix at the K/V secret engine. 
For each KES tenant there has to be a corresponding Vault policy.

- For K/V `v1`:
  ```hcl {.copy}
  path "kv/<tenant-name>/*" {
     capabilities = [ "create", "read", "delete" ]
  }
  ```

- For K/V `v2`:
  ```hcl {.copy}
  path "kv/data/<tenant-name>/*" {
     capabilities = [ "create", "read" ]
  }
  path "kv/metadata/<tenant-name>/*" {
     capabilities = [ "list", "delete" ]       
  }
  ```

Use a different configuration file for each KES tenant.
The file contains the Vault namespace which the KES tenant should use.

```yaml {.copy}
keystore:
   vault:
     endpoint: https://127.0.0.1:8200
     namespace: <vault-namespace>
     approle:
       id:     "" # Your AppRole ID
       secret: "" # Your AppRole Secret
       retry:  15s
     status:
       ping: 10s
     tls:
       ca: vault.crt # Manually trust the vault certificate since we use self-signed certificates
```

### Encrypt Vault-stored Keys

Hashicorp's [Transit](https://developer.hashicorp.com/vault/docs/secrets/transit) functionality provides a means to encrypt and decrypt keys stored in the vault.
This provides an additional layer of encryption that may be useful in specific use cases.

When enabled, Hashicorp stores a key in the Vault to encrypt or decrypt the other keys stored in the vault.
KES then uses the vault-managed key to store or retrieve keys from the Vault.

{{< admonition type="warning" >}}
If the specified transit key is incorrect, disabled, removed, or otherwise unaccessible, KES cannot retrieve any vault keys nor perform any en/decryption operations relying on those keys.
{{< /admonition >}}

To configure Transit, add the following section to the KES Configuration YAML's `keystore.vault` section:

```sh {.copy}
keystore:
  vault:
    transit:      # Optionally encrypt keys stored on the K/V engine with a Vault-managed key.
      engine: ""  # The path of the transit engine - e.g. "my-transit". If empty, defaults to: transit (Vault default)
      key: ""     # The key name that should be used to encrypt entries stored on the K/V engine.
```

## References

- [Server API Doc]({{< relref "/concepts/server-api" >}})
- [Go SDK Doc](https://pkg.go.dev/github.com/minio/kes)